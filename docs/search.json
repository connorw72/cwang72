[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Connor Wang",
    "section": "",
    "text": "Hello! My name is Connor. I am a sophomore at Pomona College pursuing a Computer Science degree with a minor in data science. Outside of school I am on the Pomona-Pitzer football, where we compete in the SCIAC. My hobbies include going to the gym, playing video games, and spending time with friends."
  },
  {
    "objectID": "project5.html",
    "href": "project5.html",
    "title": "Arrests and Warnings categorized by race across the states of Arizona, Maryland, and Colorado",
    "section": "",
    "text": "R Packages\nlibrary(ggplot2) # R package\nEstablish Database Connection\ncon_traffic &lt;- DBI::dbConnect( # connection to database\n  RMariaDB::MariaDB(),\n  dbname = \"traffic\",\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)"
  },
  {
    "objectID": "project5.html#introduction",
    "href": "project5.html#introduction",
    "title": "Arrests and Warnings categorized by race across the states of Arizona, Maryland, and Colorado",
    "section": "Introduction",
    "text": "Introduction\nWhen a traffic stop is made, a cop can choose to arrest an individual, write them a citation, or give them a warning. A warning is the most minor, while a citation tends to mean a fine and other possible punishments, with an arrest being the worst as there is more reason to believe that a true crime has been committed. Using the Stanford Open Policing Project, I wanted to explore data regarding the number of warnings, citations, and arrests made based on race in various states. I thought this was interesting and important to look at to see if there are any trends based on the severity of the punishment given to an individual and their race. Given the diversity of the United States of America, I chose to use 3 states that represented different areas of the country - the west, through Arizona, the midwest through Colorado, and the east coast, through Maryland. Although they have different populations, with Arizona over a million people more than the next one, Maryland, I thought it was best to get a good representation of different regions of the country. I split the data up based on the punishment given to the person who was stopped, which I then used to create a bar graphs with side by side comparisons split by race and state.\n\nSELECT 'Maryland' AS state, \n  subject_race,\n  COUNT(*) AS total_stops,\n  SUM(arrest_made) AS num_arrests,\n  SUM(arrest_made) * 1.0 / COUNT(*) AS arrest_rate\nFROM md_statewide_2020_04_01\nWHERE arrest_made = 1\nGROUP BY subject_race \nHAVING num_arrests &gt; 300\n\n\n5 records\n\n\n\n\n\n\n\n\n\nstate\nsubject_race\ntotal_stops\nnum_arrests\narrest_rate\n\n\n\n\nMaryland\nasian/pacific islander\n912\n912\n1\n\n\nMaryland\nblack\n24420\n24420\n1\n\n\nMaryland\nhispanic\n6477\n6477\n1\n\n\nMaryland\nother\n921\n921\n1\n\n\nMaryland\nwhite\n32793\n32793\n1\n\n\n\n\n\n\nSELECT 'Maryland' AS state, subject_race, COUNT(*) AS num_arrests\nFROM md_statewide_2020_04_01\nWHERE arrest_made = 1\nGROUP BY subject_race \nHAVING num_arrests &gt; 300\n\nUNION\n\nSELECT 'Arizona' AS state, subject_race, COUNT(*) AS num_arrests\nFROM az_statewide_2020_04_01\nWHERE arrest_made = 1\nGROUP BY subject_race \nHAVING num_arrests &gt; 300\n\nUNION\n\nSELECT 'Colorado' AS state, subject_race, COUNT(*) AS num_arrests\nFROM co_statewide_2020_04_01\nWHERE arrest_made = 1\nGROUP BY subject_race \nHAVING num_arrests &gt; 300\n\nThe SQL query creates a table with information regarding the number of arrests made in Maryland, Colorado, and Arizona, categorized by race. The information is limited to racial groups with over 300 arrests, because lower values included “other” or “unknown”. It is compiled into one table, where it displays each state, with the top data point representing the race that had the most arrests made in that state. It is then put into the table “arrests_table” which is used to create the visualization of the arrests made.\n\nggplot(arrests_table, aes(x = subject_race, y = num_arrests, fill = state)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Number of arrests by race across the states \\n\n    Arizona, Colorado, and Maryland\",\n    x = \"Race\",\n    y = \"Number of Arrests\"\n  )\n\n\n\n\n\n\n\n\nThe bar graph represents the number of arrests made by race, with each race having three bars representative of the different states. Arizona has the most arrests made for every race. Although this can be attributed to its larger population, the number of arrests made are also much larger than the other states. Maryland had similar numbers of arrests made for both Black and White people, while the other states had much more arrests made on White people than made on Black people. The number of White people is the highest race arrested for each state, which is likely due to population makeup. Overall, there does not seem to be any alarming trends in the arrests made by state.\n\nSELECT 'Maryland' AS state, subject_race, COUNT(*) AS num_citations\nFROM md_statewide_2020_04_01\nWHERE citation_issued = 1\nGROUP BY subject_race \nHAVING num_citations &gt; 1000\n\nUNION\n\nSELECT 'Arizona' AS state, subject_race, COUNT(*) AS num_citations\nFROM az_statewide_2020_04_01\nWHERE citation_issued = 1\nGROUP BY subject_race \nHAVING num_citations &gt; 1000\n\nUNION\n\nSELECT 'Colorado' AS state, subject_race, COUNT(*) AS num_citations\nFROM co_statewide_2020_04_01\nWHERE citation_issued = 1\nGROUP BY subject_race \nHAVING num_citations &gt; 1000\n\nThe SQL query creates a table with information regarding the number of citations given in Maryland, Colorado, and Arizona, categorized by race. The information is limited to racial groups with over 1000 citations, because lower values included “other” or “unknown”. It is compiled into one table, where it displays each state, with the top data point representing the race that had the most citations given in that state. It is then put into the table “citations_table” which is used to create the visualization of the citations given.\n\nggplot(citations_table, aes(x = subject_race, y = num_citations, fill = state)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Number of citations given by race across the states \\n \n    Maryland, Arizona, and Colorado\",\n    x = \"Race\",\n    y = \"Number of Citations Issued\"\n  )\n\n\n\n\n\n\n\n\nThe bar graph represents the number of citations made by race, with each race having three bars to represent the different states. Arizona has an overwhelmingly high number of citations given to White and Hispanic people, while Maryland gave the most citations to Black people. A clear difference is seen in Maryland and Arizona, where the numbers of citations given to White people and Black people are similar in Maryland, while much more White people were given citations than Black people in Arizona. The difference between Hispanic and White in Arizona is quite substantial as well, with the number of citations written to Hispanic people about half that of White people. Based on our data, we can see that it is constant across the states for White people to be written the most citations.\n\nSELECT 'Maryland' AS state, subject_race, COUNT(*) AS num_warnings\nFROM md_statewide_2020_04_01\nWHERE warning_issued = 1\nGROUP BY subject_race \nHAVING num_warnings &gt; 5000 \n\nUNION\n\nSELECT 'Arizona' AS state, subject_race, COUNT(*) AS num_warnings\nFROM az_statewide_2020_04_01\nWHERE warning_issued = 1\nGROUP BY subject_race \nHAVING num_warnings &gt; 5000 \n\nUNION \n\nSELECT 'Colorado' AS state, subject_race, COUNT(*) AS num_warnings\nFROM co_statewide_2020_04_01\nWHERE warning_issued = 1\nGROUP BY subject_race \nHAVING num_warnings &gt; 5000 \n\nThe SQL query creates a table with information regarding the number of warnings given in Maryland, Colorado, and Arizona, categorized by race. The information is limited to racial groups with over 5000 warnings, because lower values included “other” or “unknown”. It is compiled into one table, where it displays each state, with the top data point representing the race that had the most warnings given in that state. It is then put into the table “warnings_table” which is used to create the visualization of the warnings given.\n\nggplot(warnings_table, aes(x = subject_race, y = num_warnings, fill = state)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Number of warnings given by race across the states \\n\n    Arizona, Colorado, and Maryland\",\n    x = \"State\",\n    y = \"Number of Warnings issued\"\n  )\n\n\n\n\n\n\n\n\nThe bar graph represents the number of warnings issued by race, with each race having three bars to separate data amongst the states. Likely as a result of population differences, White people have the highest number of warnings issued to them across all states. The second highest for the state of Maryland is Black people, while the second highest for Arizona is Hispanic. In Colorado, the second is Hispanic however it is much less than that of White people. It could be a reflection of the proportion of the population, but the difference in citations for Black people and White people is substantial in Arizona and Colorado, however not as far off in Maryland."
  },
  {
    "objectID": "project5.html#conclusion",
    "href": "project5.html#conclusion",
    "title": "Arrests and Warnings categorized by race across the states of Arizona, Maryland, and Colorado",
    "section": "Conclusion",
    "text": "Conclusion\nIn order to create our visualizations of arrests made, citations issued, and warnings given by race across the states of Arizona, Maryland, and Colorado in traffic stops, I utilized SQL queries. Each dataset had a variable pertaining to arrests, citations, or warnings. I extracted number of each that was given, grouping by race in order to give the total number of each category given by race. I then used union to combine data and create tables for each type of punishment given. I followed the same steps for each arrests, citations, and warnings, where the variable was given a value of 1 if it was the outcome, and 0 if it was not, so 1 was seen as a datapoint that I wanted to track. I then removed the lowest numbers by race, as they were often just the “other” or “unknown” category, so the data was not extremely useful. From these combined tables I then created the graphs to visualize the data and look for any clear trends."
  },
  {
    "objectID": "project5.html#references",
    "href": "project5.html#references",
    "title": "Arrests and Warnings categorized by race across the states of Arizona, Maryland, and Colorado",
    "section": "References",
    "text": "References\nPierson, Emma, Camelia Simoiu, Jan Overgoor, Sam Corbett-Davies, Daniel Jenson, Amy Shoemaker, Vignesh Ramachandran, et al. 2020. “A Large-Scale Analysis of Racial Disparities in Police Stops Across the United States.” Nature Human Behaviour, 1–10."
  },
  {
    "objectID": "dataviz/horrormovies.html",
    "href": "dataviz/horrormovies.html",
    "title": "Horror Movies",
    "section": "",
    "text": "With the purpose of exploring a dataset about horror movies dating back to the 1950s, Tasha Piro(2022) accessed data from The Movie Database. The data from Piro was then widely spread by Jon Harmon(2022) for the purpose of TidyTuesday. The movie industry is an important part of American society. Films provide sources of entertainment, education, emotional expression, as well as an activity for people of all ages to participate in. It is interesting to see how different movies fare, and how much money successful movies can make. For this analysis, I have chosen to look into the horror genre, and analyze differences in budgets and revenue across different horror movies, including ones that did and did not do well in the box office. Generally, you would expect movies that have more money invested into them to be better, and thus perform better in theatres and gain more revenue. However, there are always those few movies that have low budget and blow others out of the water as a result of clever writing and good storytelling. In order to see any possible trends regarding this, we using the “horror_movies” dataset, which included information on both budget and revenue of different horror movies. We then plotted these to check for any relationship between the two, assuming that higher budgets would lead to higher revenues.\nHorror Movies Dataset\nlibrary(tidyverse)\nhorror_movies &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2022/2022-11-01/horror_movies.csv') # read data\nTibble of data\nhead(horror_movies) # display head of data\n\n\n# A tibble: 6 × 20\n       id original_title   title original_language overview tagline release_date\n    &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;             &lt;chr&gt;    &lt;chr&gt;   &lt;date&gt;      \n1  760161 Orphan: First K… Orph… en                After e… There'… 2022-07-27  \n2  760741 Beast            Beast en                A recen… Fight … 2022-08-11  \n3  882598 Smile            Smile en                After w… Once y… 2022-09-23  \n4  756999 The Black Phone  The … en                Finney … Never … 2022-06-22  \n5  772450 Presencias       Pres… es                A man w… &lt;NA&gt;    2022-09-07  \n6 1014226 Sonríe           Sonr… es                &lt;NA&gt;     &lt;NA&gt;    2022-08-18  \n# ℹ 13 more variables: poster_path &lt;chr&gt;, popularity &lt;dbl&gt;, vote_count &lt;dbl&gt;,\n#   vote_average &lt;dbl&gt;, budget &lt;dbl&gt;, revenue &lt;dbl&gt;, runtime &lt;dbl&gt;,\n#   status &lt;chr&gt;, adult &lt;lgl&gt;, backdrop_path &lt;chr&gt;, genre_names &lt;chr&gt;,\n#   collection &lt;dbl&gt;, collection_name &lt;chr&gt;\nThe table represents a tibble of the first several rows from the dataset. The data includes 20 columns, with data such as title, language, overview, release date, budget, revenue, and more about each movie. Each row is a different horror movie.\nPlot Code\nggplot(horror_movies, aes(x = budget, y = revenue)) + # got budget and revenue data from dataset\n  geom_point(color = \"red\") + #create scatterplot with red points\n  labs( # set plot labels \n    title = \"Horror Movie Budget versus Revenue\",\n    x = \"Budget\",\n    y = \"Revenue\"\n  )\nThe scatterplot above uses our “horror_movies” dataset to plot the budget of a movie on the x-axis, with revenue displayed on the y-axis. We would expect to see a relationship where the movies with a higher budget, further along the x-axis, would have the highest revenue values on the y-axis. This was not necessarily the case, as the movie that raked in the most revenue had a lower budget than many other movies. The majority of the horror movies do not have large budgets, and thus generate similar revenues. We do not see a trend that putting more money into a movie will necessarily mean more revenue. It is more important to have an intriguing story, good acting, and create a good movie than pour too much money into it."
  },
  {
    "objectID": "dataviz/horrormovies.html#references",
    "href": "dataviz/horrormovies.html#references",
    "title": "Horror Movies",
    "section": "References",
    "text": "References\nHarmon, Jon. “Horror Movies.” tidytuesday, 11 Jan. 2022, https://github.com/rfordatascience/tidytuesday/tree/main/data/2022/2022-11-01.\nPiro, Tasha. “Horror Movies.” Github, 2022, https://github.com/tashapiro/horror-movies.\n“TMDB.” The Movie Database (TMDB), https://www.themoviedb.org/. Accessed 7 May 2025."
  },
  {
    "objectID": "presentation.html#project-1---data-visualization",
    "href": "presentation.html#project-1---data-visualization",
    "title": "Final Presentation",
    "section": "Project 1 - Data Visualization",
    "text": "Project 1 - Data Visualization\n\nOverviewBob’s BurgersHorror Movies\n\n\n\nTwo TidyTuesday datasets\nData on Bob’s Burgers Dialogue from various episodes.\nData on how Horror Movies performed in the box office/how much the public enjoyed them.\n\n\n\n\nAmerican Sitcom with 15 seasons\nFollows Bob Belcher and his family, who own the restaurant Bob’s Burgers\n\n\n# A tibble: 6 × 8\n  season episode dialogue_density avg_length sentiment_variance unique_words\n   &lt;dbl&gt;   &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;              &lt;dbl&gt;        &lt;dbl&gt;\n1      1       1            0.930       37.5               3.32          960\n2      1       2            0.994       33.8               3.99          950\n3      1       3            0.992       31.1               4.08          915\n4      1       4            0.994       32.2               3.71          892\n5      1       5            0.994       34.1               3.78          888\n6      1       6            0.994       33.2               3.30          921\n# ℹ 2 more variables: question_ratio &lt;dbl&gt;, exclamation_ratio &lt;dbl&gt;\n\n\nExplored a possible relationship between the amount of lines that ended with questions versus exclamations\n\n\nggplot(episode_metrics, aes(x = question_ratio, y = exclamation_ratio)) +\n  geom_point(color = \"blue\") + \n  labs(\n    title = \"Question Ratio vs. Exclamation Ratio in Bob's Burgers episodes\",\n    x = \"Ratio of lines with questions\",\n    y = \"Ratio of lines with exclamations\"\n  )\n\n\n\n\n\n\n\n\n\nNo clear trends from scatterplot, more questions does not mean more excitement in an epsiode.\n\n\n\n\nPopular genre of movies meant to evoke feelings of fear and terror\nSince 2017, around 40+ horror movies are released each year\n\n\n# A tibble: 6 × 20\n       id original_title   title original_language overview tagline release_date\n    &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;             &lt;chr&gt;    &lt;chr&gt;   &lt;date&gt;      \n1  760161 Orphan: First K… Orph… en                After e… There'… 2022-07-27  \n2  760741 Beast            Beast en                A recen… Fight … 2022-08-11  \n3  882598 Smile            Smile en                After w… Once y… 2022-09-23  \n4  756999 The Black Phone  The … en                Finney … Never … 2022-06-22  \n5  772450 Presencias       Pres… es                A man w… &lt;NA&gt;    2022-09-07  \n6 1014226 Sonríe           Sonr… es                &lt;NA&gt;     &lt;NA&gt;    2022-08-18  \n# ℹ 13 more variables: poster_path &lt;chr&gt;, popularity &lt;dbl&gt;, vote_count &lt;dbl&gt;,\n#   vote_average &lt;dbl&gt;, budget &lt;dbl&gt;, revenue &lt;dbl&gt;, runtime &lt;dbl&gt;,\n#   status &lt;chr&gt;, adult &lt;lgl&gt;, backdrop_path &lt;chr&gt;, genre_names &lt;chr&gt;,\n#   collection &lt;dbl&gt;, collection_name &lt;chr&gt;\n\n\nExplored relationship between a movie’s budget and revenue\n\n\nggplot(horror_movies, aes(x = budget, y = revenue)) +\n  geom_point(color = \"red\") +\n  labs(\n    title = \"Horror Movie Budget versus Revenue\",\n    x = \"Budget\",\n    y = \"Revenue\"\n  )\n\n\n\n\n\n\n\n\n\nNo clear trends from scatterplot, spending more money does not necessarily mean you will make more money."
  },
  {
    "objectID": "presentation.html#project-2---netflix-data-analysis",
    "href": "presentation.html#project-2---netflix-data-analysis",
    "title": "Final Presentation",
    "section": "Project 2 - Netflix Data Analysis",
    "text": "Project 2 - Netflix Data Analysis\n\nNetflix is a popular streaming service consisting of TV shows, documentaries, movies, and more.\n\n\n\n# A tibble: 6 × 12\n  show_id type    title director    cast  country date_added release_year rating\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt; \n1 s1      TV Show 3%    &lt;NA&gt;        João… Brazil  August 14…         2020 TV-MA \n2 s2      Movie   7:19  Jorge Mich… Demi… Mexico  December …         2016 TV-MA \n3 s3      Movie   23:59 Gilbert Ch… Tedd… Singap… December …         2011 R     \n4 s4      Movie   9     Shane Acker Elij… United… November …         2009 PG-13 \n5 s5      Movie   21    Robert Luk… Jim … United… January 1…         2008 PG-13 \n6 s6      TV Show 46    Serdar Akar Erda… Turkey  July 1, 2…         2016 TV-MA \n# ℹ 3 more variables: duration &lt;chr&gt;, listed_in &lt;chr&gt;, description &lt;chr&gt;\n\n\n\nCreated three questions of interest regarding the information from the dataset."
  },
  {
    "objectID": "presentation.html#has-movie-duration-changed-over-time",
    "href": "presentation.html#has-movie-duration-changed-over-time",
    "title": "Final Presentation",
    "section": "Has movie duration changed over time?",
    "text": "Has movie duration changed over time?\n\nData from the mid 1900s to 2022.\nFilms from multiple countries and genres on Netflix.\nManipulated data to include only movies that have a runtime of a hour or longer.\n\nmovies_only &lt;- netflix_titles %&gt;%\n  filter(type == \"Movie\") %&gt;%\n  mutate(movie_duration = as.numeric(str_extract(duration, \"\\\\d+\"))) %&gt;%\n  filter(!is.na(duration) & movie_duration &gt;= 60)%&gt;%\n  arrange(release_year)%&gt;%\n  select(type, release_year, duration, movie_duration)\n\nhead(movies_only)\n\n# A tibble: 6 × 4\n  type  release_year duration movie_duration\n  &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;\n1 Movie         1943 61 min               61\n2 Movie         1943 82 min               82\n3 Movie         1944 76 min               76\n4 Movie         1945 63 min               63\n5 Movie         1954 116 min             116\n6 Movie         1954 120 min             120\n\n\n\nggplot(movies_only, aes(x = release_year, y = movie_duration)) + \n  geom_point(color = \"lightsalmon3\") +\n  labs(\n    title = \"Has Movie duration changed over time?\",\n    x = \"Year Released\",\n    y = \"Duration of Movie in Minutes(starting at 60)\"\n  )\n\n\n\n\n\n\n\n\nFound no trend, movie durations have stayed in a similar range over the years."
  },
  {
    "objectID": "presentation.html#movies-and-shows-about-the-future",
    "href": "presentation.html#movies-and-shows-about-the-future",
    "title": "Final Presentation",
    "section": "Movies and Shows about the future",
    "text": "Movies and Shows about the future\n\nDataset included a brief description about each piece of media.\nAnalyzed the number of films, TV shows, documentaries, etc. that were about the future categorized by country.\n\ncontent_about_future &lt;- netflix_titles %&gt;%\n  filter(str_detect(description, \"(?i)future\")) %&gt;%\n  filter(!is.na(country)) %&gt;%\n  group_by(country) %&gt;%\n  summarise(count = sum(n())) %&gt;%\n  arrange(desc(count)) %&gt;%\n  slice_head(n = 10)\n\nhead(content_about_future)\n\n# A tibble: 6 × 2\n  country        count\n  &lt;chr&gt;          &lt;int&gt;\n1 United States     30\n2 India              9\n3 United Kingdom     5\n4 Indonesia          4\n5 Canada             3\n6 South Korea        3\n\n\n```{ggplot(content_about_future, aes(x = country, y = count)) +} geom_col(fill = “plum3”) + labs( title = “Countries with TV Shows and Movies about the ‘future’”, x = “Country”, y = “Number of TV Shows/Movies” ) + theme(axis.text.x = element_text(size = 7))\n```\nUnited States had the most, but likely because most of the media was from the US to begin with.\nMost countries are similar, no country is overly creative about the future."
  },
  {
    "objectID": "presentation.html#words-preceding-of",
    "href": "presentation.html#words-preceding-of",
    "title": "Final Presentation",
    "section": "Words preceding ‘of’",
    "text": "Words preceding ‘of’\n\nDataset included titles of many different works of media.\nAnalyzed which words most commonly came before ‘of’ in a title.\nChose ‘of’ because of how common it is used - ex: story of, legend of, etc.\n\nwords &lt;- netflix_titles %&gt;%\n  mutate(of = str_extract(str_to_lower(title), \"\\\\b\\\\w+(?= of)\")) %&gt;%\n  filter(!is.na(of)) %&gt;%\n  group_by(of) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(desc(n)) %&gt;%\n  slice_head(n = 10)\nhead(words)\n\n# A tibble: 6 × 2\n  of          n\n  &lt;chr&gt;   &lt;int&gt;\n1 legend     19\n2 story      19\n3 secrets    16\n4 life       11\n5 tales      11\n6 age         8\n\n\n\nggplot(words, aes(x = of, y = n)) +\n  geom_col(aes(fill = of)) + \n  labs(\n    title = \"10 Most common words that come before 'of' in TV show/movie titles\",\n    x = \"Word before 'of'\",\n    y = \"Number of titles that it appears before 'of' in\"\n  )\n\n\n\n\n\n\n\n\nMost common words were (as predicted) legend, story.\nSimilar movie title formats are recycled."
  },
  {
    "objectID": "dataviz/bobsburgers.html",
    "href": "dataviz/bobsburgers.html",
    "title": "Bobs Burgers",
    "section": "",
    "text": "Using data compiled by Steven Ponce(2024), Jon Harmon(2024) curated a dataset consisting of dialogue information from Bob’s Burgers episodes for the purpose of TidyTuesday. Ponce collected this data through three sources, Schlesinger and Benjamin on Wikipedia, IMDb, and Springfield! Springfield! Bob’s Burgers is an American Sitcom that debuted in 2011. The show follows Bob Belcher, his wife, and his three kids as he works to the restaurant he inherited, Bob’s Burgers, up and running. The show has found great success, airing 15 seasons over the years. The show debuted on Fox, where it continues to air, and can be found on various streaming services. The successful comedy is full of hilarious, clever dialogue which has allowed it to continue for 15 seasons. The dataset which is called “episode_metrics” contains data on various lines from different seasons and episodes of Bob’s Burgers. Using the data, I chose to explore a possible connection between lines with questions and lines with exclamations. If an episode has more questions asked, then there is a higher chance of more lines with exclamations which can often be punch lines or lines with more meaning. This would tell us more about the Bob’s Burgers series and find possible patterns in the way the writers are thinking when they work on the script. If more questions leads to more exclamations, then there is likely a writer technique/comedy reasons for why this happens.\nBobs Burgers Dataset\nlibrary(tidyverse) # \n\nepisode_metrics &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-11-19/episode_metrics.csv') # read data\nTibble of data\nhead(episode_metrics) # display head of data\n\n\n# A tibble: 6 × 8\n  season episode dialogue_density avg_length sentiment_variance unique_words\n   &lt;dbl&gt;   &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;              &lt;dbl&gt;        &lt;dbl&gt;\n1      1       1            0.930       37.5               3.32          960\n2      1       2            0.994       33.8               3.99          950\n3      1       3            0.992       31.1               4.08          915\n4      1       4            0.994       32.2               3.71          892\n5      1       5            0.994       34.1               3.78          888\n6      1       6            0.994       33.2               3.30          921\n# ℹ 2 more variables: question_ratio &lt;dbl&gt;, exclamation_ratio &lt;dbl&gt;\nThe table represents a tibble of the first several rows from the dataset. The data includes 8 columns, with information regarding season, episode, dialogue density, average length, sentiment variance, unique words, question ratio, and exclamation ratio. Each row is an episode of Bob’s burgers.\nPlot Code\nggplot(episode_metrics, aes(x = question_ratio, y = exclamation_ratio)) + # takes question_ratio and exclamation_ratio from dataset to set x and y axis\n  geom_point(color = \"blue\") + # creates scatterplot with blue points\n  labs( # sets labels\n    title = \"Question Ratio vs. Exclamation Ratio in Bob's Burgers episodes\",\n    x = \"Ratio of lines with questions\",\n    y = \"Ratio of lines with exclamations\"\n  )\nThe scatterplot above represents the ratio of lines with questions, on the x-axis, compared to the ratio of lines with exclamations, on the y-axis. These dots represent different episodes across various seasons. From the data, we do not see any clear trends with regards to how many questions are asked and how many exclamations there are in a given episode. As a result, we see that there is likely no correlation between the two. It is just random based on what is happening in an episode, and what the writers believe is necessary in terms of how the dialogue of the episode will flow."
  },
  {
    "objectID": "dataviz/bobsburgers.html#references",
    "href": "dataviz/bobsburgers.html#references",
    "title": "Bobs Burgers",
    "section": "References",
    "text": "References\n“Bob’s Burgers Episode Scripts.” Springfield! Springfield!, https://www.springfieldspringfield.co.uk/episode_scripts.php?tv-show=bobs-burgers.\n“Bob’s Burgers (TV Series 2011– ) - Episode list.” IMDb, https://www.imdb.com/title/tt1561755/episodes/?season=1. Accessed 7 May 2025.\nHarmon, Jon. “Bob’s Burgers Episodes.” tidytuesday, 19 Nov. 2024, https://github.com/rfordatascience/tidytuesday/blob/main/data/2024/2024-11-19/readme.md.\nPonces, Steven. 2024, “bobsburgersR.” tidytuesday, https://github.com/poncest/bobsburgersR.\nSchlesinger, Holly, and Benjamin, Jon. “List of Bob’s Burgers episodes.” Wikipedia, https://en.wikipedia.org/wiki/List_of_Bob%27s_Burgers_episodes#Episodes. Accessed 7 May 2025."
  },
  {
    "objectID": "project4.html",
    "href": "project4.html",
    "title": "Exploring Bias in an Amazon Hiring AI",
    "section": "",
    "text": "Back in 2014 a team of Amazon engineers developed an experimental hiring tool that used artificial intelligence to help sort through job applications. The model was meant to increase efficiency by automatically scoring resumes without the need for a human to spend time reading through them. Candidates were given scores from one to five stars, in order to highlight the most promising candidates for recruiters to look at (Dastin). The team utilized resumes from the past ten years submitted to the company to train the model. The algorithm then learned patterns from this data to predict strong candidates, based on past hirings. Issues arose when the company noticed that the ratings were systematically discriminating against women when they applied for technical jobs (Goodman). Given that the program used past Amazon resumes as blueprints for what an ideal resume looks like, and that males dominated the tech industry at the time, the algorithm learned to favor male applicants. The male candidates were preferred due to various keywords, such as “captured”, which were verbs that were more common for male engineers to use. Women candidates were penalized for mentioning the word “women’s” in relation to clubs or teams, and discriminated against all-women’s colleges (Goodman). As a result of this bias, Amazon stopped using this particular software program and moved on to a recruiting engine that would help with more “rudimentary chores” (Dastin). The overall idea of the algorithm made sense - take in lots of data, and use it to train the model to look out for what Amazon has considered a successful candidate in the past. When doing so, it takes out the human aspect of looking through resumes and getting a feel for the person submitting the job application. The model was just going off the data it was given, which happened to be predominantly male resumes."
  },
  {
    "objectID": "project4.html#the-scenario",
    "href": "project4.html#the-scenario",
    "title": "Exploring Bias in an Amazon Hiring AI",
    "section": "",
    "text": "Back in 2014 a team of Amazon engineers developed an experimental hiring tool that used artificial intelligence to help sort through job applications. The model was meant to increase efficiency by automatically scoring resumes without the need for a human to spend time reading through them. Candidates were given scores from one to five stars, in order to highlight the most promising candidates for recruiters to look at (Dastin). The team utilized resumes from the past ten years submitted to the company to train the model. The algorithm then learned patterns from this data to predict strong candidates, based on past hirings. Issues arose when the company noticed that the ratings were systematically discriminating against women when they applied for technical jobs (Goodman). Given that the program used past Amazon resumes as blueprints for what an ideal resume looks like, and that males dominated the tech industry at the time, the algorithm learned to favor male applicants. The male candidates were preferred due to various keywords, such as “captured”, which were verbs that were more common for male engineers to use. Women candidates were penalized for mentioning the word “women’s” in relation to clubs or teams, and discriminated against all-women’s colleges (Goodman). As a result of this bias, Amazon stopped using this particular software program and moved on to a recruiting engine that would help with more “rudimentary chores” (Dastin). The overall idea of the algorithm made sense - take in lots of data, and use it to train the model to look out for what Amazon has considered a successful candidate in the past. When doing so, it takes out the human aspect of looking through resumes and getting a feel for the person submitting the job application. The model was just going off the data it was given, which happened to be predominantly male resumes."
  },
  {
    "objectID": "project4.html#consent",
    "href": "project4.html#consent",
    "title": "Exploring Bias in an Amazon Hiring AI",
    "section": "Consent",
    "text": "Consent\nWhen using participant data for research or training a model, it is important that the individual consents to their data being used. Since data can include personal information that participants may want to keep private, they must know where their data will be going and how it will be used. They must allow for their data to be used in this way, or state they are fine with the company using their data in any way. In this case, given that resumes from ten years back were used, it is highly unlikely that job applicants signed on to have their resumes included as data when attempting to train this hiring model (Goodman). The individuals submitted the job applications expecting a human recruiter to read and evaluate their resumes, not to be used for a machine learning experiment. Given that Large Language Models and AI were not as prominent in the period when they used these job applications, we can assume that applicants did not give informed consent for their resumes to be used for a model. The applicants are unaware of the context in which their data is being used. Although they were willingly submitting their personal information in the form of job applications and resumes, we do not know if they ever meaningfully said that it was okay to use their data to train the model. Thus, it is difficult to get consent for unforeseen application data."
  },
  {
    "objectID": "project4.html#unintended-use",
    "href": "project4.html#unintended-use",
    "title": "Exploring Bias in an Amazon Hiring AI",
    "section": "Unintended Use",
    "text": "Unintended Use\nOftentimes, data can be used in ways that the user did not originally intend. In the example of the Amazon model, data was used that the user submitted for the purpose of getting hired, not to train a hiring model (Dastin). The primary issue with unintended use is that users will submit data for one purpose, but it ends up being used for another. In this case, similar to the aforementioned consent case, the repurposing of this data, which was not originally meant to be used for this model, ended up having unintended consequences. It is necessary to ensure that data being used for a different circumstance than originally intended is valid and can be used in this context. Since the data was just for various Amazon job applications, the model recognized the past hiring patterns, which happened to be in a male-dominated field. The applicants and engineers did not mean for these harms to occur, yet they occurred because the data was used in a way that it was not supposed to be."
  },
  {
    "objectID": "project4.html#generalization-of-the-data",
    "href": "project4.html#generalization-of-the-data",
    "title": "Exploring Bias in an Amazon Hiring AI",
    "section": "Generalization of the Data",
    "text": "Generalization of the Data\nWhen looking at data, it is important to keep in mind what we are analyzing it for. The data that we are using should be representative of the people who will eventually be affected by the algorithm to make sure it accurately makes predictions for the representative population. Otherwise, we could be using data that is completely unrelated or missing a part of the representative population, and thus creating an algorithm that does not correctly apply. Using a dataset of Amazon’s previous tech industry hiring history meant one that consisted of predominantly male resumes (Dastin). This meant training data for the model that was not representative of the population, which in this case was Amazon’s applicant pool for tech-related jobs. Based on data that was not generalizable to the whole applicant pool, the model was flawed with gender biases coming from patterns or language that is found in male resumes. The model was going off the data it had, creating a lack of accuracy when it came to gender-diverse applicants. Attempting to make generalizations off of a non-representative dataset can be dangerous when attempting to build models that make big decisions, such as who to hire."
  },
  {
    "objectID": "project4.html#recognize-and-mitigate-bias",
    "href": "project4.html#recognize-and-mitigate-bias",
    "title": "Exploring Bias in an Amazon Hiring AI",
    "section": "Recognize and Mitigate Bias",
    "text": "Recognize and Mitigate Bias\nThe data values and principles manifesto states that you must try to recognize and mitigate bias in the data that we are using. Given what ultimately happened with the model, it is clear that the Amazon team did not take the steps necessary to mitigate bias. When gathering data, it is important to ask yourself if it could have any bias. Since you have details about the data you are gathering and will have the opportunity to look at it, it is necessary to do a thorough job of making sure no bias can come when training a model. Gathering resumes for a tech-related position in the early 2000s should automatically raise concerns about the groups of applicant data you will be obtaining. It should not have been hard to recognize that gender could play a significant role, and be mitigated by trying to ensure equal amounts of both male and female resumes in the data when training the model. The model failed for one reason - bias. A bias that was easily identifiable if the team stopped and asked themselves if the data they were using could lead to issues such as these. If they categorized resumes by gender, there would likely have been glaring differences between the number of male and female resumes. This was a step that the Amazon team either skipped or did not look into hard enough, and eventually paid the price.\n\nReferences\nDastin, Jeffrey. Insight - Amazon Scraps Secret AI Recruiting Tool That Showed Bias against Women | Reuters, www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G/. Accessed 4 May 2025.\nGoodman, Rachel. “Why Amazon’s Automated Hiring Tool Discriminated against Women: ACLU.” American Civil Liberties Union, 27 Feb. 2023, www.aclu.org/news/womens-rights/why-amazons-automated-hiring-tool-discriminated-against."
  },
  {
    "objectID": "project2.html",
    "href": "project2.html",
    "title": "Netflix Data Analysis",
    "section": "",
    "text": "R Packages\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n\n\nDataset\nUsing the now discontinued third party Netflix search system, Flixable, Shivam Bansal (2021) compiled a dataset with information regarding media on the streaming platform. They posted it to Kaggle, the online platform for Data Scientists and Machine Learning purposes, likely with the hope of gaining interactions in the form of views, downloads, and engagement. The dataset was taken from Kaggle by Jon Harmon (2021) for the purpose of TidyTuesday. Netflix is a streaming service which includes various documentaries, TV shows, movies, and more. Through the information in the dataset I have created various questions of interest that come with accompanying visuals in order to share my findings.\n\n\nNetflix Dataset\nnetflix_titles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2021/2021-04-20/netflix_titles.csv') # load data\n\n\n\n\nTibble of data\nhead(netflix_titles) # display head of data\n\n\n# A tibble: 6 × 12\n  show_id type    title director    cast  country date_added release_year rating\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt; \n1 s1      TV Show 3%    &lt;NA&gt;        João… Brazil  August 14…         2020 TV-MA \n2 s2      Movie   7:19  Jorge Mich… Demi… Mexico  December …         2016 TV-MA \n3 s3      Movie   23:59 Gilbert Ch… Tedd… Singap… December …         2011 R     \n4 s4      Movie   9     Shane Acker Elij… United… November …         2009 PG-13 \n5 s5      Movie   21    Robert Luk… Jim … United… January 1…         2008 PG-13 \n6 s6      TV Show 46    Serdar Akar Erda… Turkey  July 1, 2…         2016 TV-MA \n# ℹ 3 more variables: duration &lt;chr&gt;, listed_in &lt;chr&gt;, description &lt;chr&gt;\n\n\nThe table represents a tibble of the first several rows of the dataset. The data includes 12 columns, with information on the type of media, the title, director, cast, country, date added, year released, rating, duration, and genre it is listed in. Each row is a title on Netflix.\n\n\nQuestion of Interest 1\nThe first question of interest that I came up with for this dataset is how has movie duration changed over time? Since the data about what is streaming on Netflix included the duration of movies in minutes as well as the year they were released, I decided it would be interesting to note how this has changed over time. Going into it I assumed that movies have gotten longer over time. Movies that come out these days seem to always be two plus hours, often being two and a half hours or even three on some of the extreme cases. Although not all movies are included on Netflix, it would still give a good idea of how movies have trended in terms of duration over time. In order to ensure a more accurate relationship, I removed all movies that did not have a runtime of over a hour. I figured that anything less meant it was a short film or some sort of documentary that would not accurately represent the runtimes of movies. Based on the scatterplot I created below there is not a clear trend in movie duration over time. Instead we see when the movie industry took off and there was a higher amount of movies being made , which occurred starting at the 2000s.\n\n\nData Filtering and Plot Creation\nmovies_only &lt;- netflix_titles %&gt;%\n  filter(type == \"Movie\") %&gt;% #movies only\n  mutate(movie_duration = as.numeric(str_extract(duration, \"\\\\d+\"))) %&gt;% # only the numbers from the duration (says min originally)\n  filter(!is.na(duration) & movie_duration &gt;= 60) # only movies 60 mins or longer\n\nggplot(movies_only, aes(x = release_year, y = movie_duration)) + #data from filtered dataset\n  geom_point(color = \"lightsalmon3\") + #scatterplot \n  labs( #graph labels\n    title = \"Has Movie duration changed over time?\",\n    x = \"Year Released\",\n    y = \"Duration of Movie in Minutes(starting at 60)\"\n  )\n\n\n\n\n\n\n\n\n\nPreviously mentioned in the description of the question of interest, this plot depicts the release year of a movie on the x-axis versus the duration of the movie in minutes on the y-axis. This creates a comparison between movie duration over time. We do not see any clear trends in terms of how movie duration has changed over time, leading us to believe that it has not. As movies progressed they maintained a similar blueprint as the original ones, keeping similar runtimes that they believed was sufficient to tell the story that they were attempting to give their viewers. They did not see a point in making the movies extremely shorter or longer as time went on.\n\n\nQuestion of Interest 2\nThe second question of interest that I came up with was which countries have the most TV Shows and Movies that are about the future. I wondered if there would be a connection to depictions of the future with countries that tend to be seen as more technologically advanced or first world. I explored the descriptions that included the word future in them and used this to determine if the picture had anything to do with the future. What I found generally aligned with what I thought as the United States had the highest amount of TV shows and movies dealing with ‘future’ ideas. This is also likely why I thought about this because I am exposed to so many shows and movies that align with this, having grown up watching Netflix in the states. The bar chart shows a large discrepancy from the United States to the next country, India. This uses only the top 10 countries that have future in descriptions.\n\n\nData Filtering and Plot Creation\ncontent_about_future &lt;- netflix_titles %&gt;%\n  filter(str_detect(description, \"(?i)future\")) %&gt;% # look for the word future in descriptions\n  filter(!is.na(country)) %&gt;% # remove titles where country is NA\n  group_by(country) %&gt;% \n  summarise(count = sum(n())) %&gt;% # group by country and count the number of times it appears\n  arrange(desc(count)) %&gt;%\n  slice_head(n = 10) # only show the top 10 countries\n\nggplot(content_about_future, aes(x = country, y = count)) + # data from filtered dataset\n  geom_col(fill = \"plum3\") + \n  labs( # labels for data\n    title = \"Countries with TV Shows and Movies about the 'future'\",\n    x = \"Country\",\n    y = \"Number of TV Shows/Movies\"\n  ) +\n  theme(axis.text.x = element_text(size = 7)) # stop text from overlapping\n\n\n\n\n\n\n\n\n\nPreviously mentioned in the description of the question of interest, this plot shows the top 10 countries that have TV Shows or Movies on Netflix with future in their description. The y-axis shows how many TV Shows or Movies follow this criteria. Outside of the United States, there are not very many TV Shows or Movies that are about future scenarios. The US is the clear leader by about 20 projects. The next is India with about 8 or 9. Most have below 5.\n\n\nQuestion of Interest 3\nThe third question of interest that I came up with was which words come before the word ‘of’ the most in movie/show titles. I thought about this because there seem to be many shows and movies that use of, such as Pirates of the Caribbean, Wizard of Oz, and many more. I found this would be an interesting thing to see. I did not have much prediction going in, but after seeing the data it makes sense. Words such as story and legend tend to come before of. Many title creators likely see it as a good way of making a fantastical-sounding title, such as the story of ___ or the legend of ___. I used the title column in the data to create a lookaround that checked for ’ of’ following the word. This is how I got the 10 most used words before ‘of’, finding an interesting trend that I do not think many people would tend to think of.\n\n\nData Filtering and Plot Creation\nwords &lt;- netflix_titles %&gt;%\n  mutate(of = str_extract(str_to_lower(title), \"\\\\b\\\\w+(?= of)\")) %&gt;% # extract the word that comes right before 'of'\n  filter(!is.na(of)) %&gt;% \n  group_by(of) %&gt;% # group by non-NA words before 'of'\n  summarise(n = n()) %&gt;% # count the number of times this word appears before 'of'\n  arrange(desc(n)) %&gt;%\n  slice_head(n = 10) # take only the top 10 words\n\nggplot(words, aes(x = of, y = n)) + # data from filtered dataset\n  geom_col(aes(fill = of)) + #create barplot with different colors for each word\n  labs( # graph labels\n    title = \"10 Most common words that come before 'of' in TV show/movie titles\",\n    x = \"Word before 'of'\",\n    y = \"Number of titles that it appears before 'of' in\"\n  )\n\n\n\n\n\n\n\n\n\nPreviously mentioned in the question of interest, this plot shows the top 10 words that come before ‘of’ in the titles of TV shows or movies. The words legend and story are both tied for first place the most amount of times it comes before the word ‘of’ in a title. The 7 other words also appear in front of ‘of’ a considerable amount of times, all of which having at least 6 projects in which they are used in the title prior to the use of ‘of’. The different words are labeled by both the x-axis and the legend. Each color corresponds to a different word that precedes ‘of’.\n\n\nReferences\nBansal, Shivam. “Netflix Movies and TV Shows.” Kaggle, 2021, https://www.kaggle.com/datasets/shivamb/netflix-shows. Accessed 7 May 2025.\n“Flixable.” Flixable, https://flixable.com/. Accessed 7 May 2025.\nHarmon, Jon. “Netflix Shows.” Github, 2021, https://github.com/rfordatascience/tidytuesday/blob/main/data/2021/2021-04-20/readme.md."
  },
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "Fast Food",
    "section": "",
    "text": "Data Scientist Ellis Hughes(2018) compiled a dataset consisting of various fast food entrees. The data came from the website “Fast Food Nutrition”, which carries data on the nutrition values of fast food items from different restaurants. At the request of the website owner, the web scraping guide was unfortunately removed. Hughes posted the dataset for the purpose of TidyTuesday.\n\n\nR packages and fastfood dataset\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nfastfood &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018/2018-09-04/fastfood_calories.csv\") # dataset\n\n\n\n\nTibble of data\nhead(fastfood) # display head of data\n\n\n# A tibble: 6 × 18\n   ...1 restaurant item             calories cal_fat total_fat sat_fat trans_fat\n  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n1     1 Mcdonalds  Artisan Grilled…      380      60         7       2       0  \n2     2 Mcdonalds  Single Bacon Sm…      840     410        45      17       1.5\n3     3 Mcdonalds  Double Bacon Sm…     1130     600        67      27       3  \n4     4 Mcdonalds  Grilled Bacon S…      750     280        31      10       0.5\n5     5 Mcdonalds  Crispy Bacon Sm…      920     410        45      12       0.5\n6     6 Mcdonalds  Big Mac               540     250        28      10       1  \n# ℹ 10 more variables: cholesterol &lt;dbl&gt;, sodium &lt;dbl&gt;, total_carb &lt;dbl&gt;,\n#   fiber &lt;dbl&gt;, sugar &lt;dbl&gt;, protein &lt;dbl&gt;, vit_a &lt;dbl&gt;, vit_c &lt;dbl&gt;,\n#   calcium &lt;dbl&gt;, salad &lt;chr&gt;\n\n\nThe table represents a tibble of the first several rows of the dataset. The data includes 18 columns, consisting of information about fast food items including the restaurant, name of the item, calories, total fat, cholesterol, sodium, and other nutrition facts. Each row is a fast food item."
  },
  {
    "objectID": "project3.html#data-source",
    "href": "project3.html#data-source",
    "title": "Fast Food",
    "section": "",
    "text": "Data Scientist Ellis Hughes(2018) compiled a dataset consisting of various fast food entrees. The data came from the website “Fast Food Nutrition”, which carries data on the nutrition values of fast food items from different restaurants. At the request of the website owner, the web scraping guide was unfortunately removed. Hughes posted the dataset for the purpose of TidyTuesday.\n\n\nR packages and fastfood dataset\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nfastfood &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018/2018-09-04/fastfood_calories.csv\") # dataset\n\n\n\n\nTibble of data\nhead(fastfood) # display head of data\n\n\n# A tibble: 6 × 18\n   ...1 restaurant item             calories cal_fat total_fat sat_fat trans_fat\n  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n1     1 Mcdonalds  Artisan Grilled…      380      60         7       2       0  \n2     2 Mcdonalds  Single Bacon Sm…      840     410        45      17       1.5\n3     3 Mcdonalds  Double Bacon Sm…     1130     600        67      27       3  \n4     4 Mcdonalds  Grilled Bacon S…      750     280        31      10       0.5\n5     5 Mcdonalds  Crispy Bacon Sm…      920     410        45      12       0.5\n6     6 Mcdonalds  Big Mac               540     250        28      10       1  \n# ℹ 10 more variables: cholesterol &lt;dbl&gt;, sodium &lt;dbl&gt;, total_carb &lt;dbl&gt;,\n#   fiber &lt;dbl&gt;, sugar &lt;dbl&gt;, protein &lt;dbl&gt;, vit_a &lt;dbl&gt;, vit_c &lt;dbl&gt;,\n#   calcium &lt;dbl&gt;, salad &lt;chr&gt;\n\n\nThe table represents a tibble of the first several rows of the dataset. The data includes 18 columns, consisting of information about fast food items including the restaurant, name of the item, calories, total fat, cholesterol, sodium, and other nutrition facts. Each row is a fast food item."
  },
  {
    "objectID": "project3.html#plan",
    "href": "project3.html#plan",
    "title": "Fast Food",
    "section": "Plan",
    "text": "Plan\nFor the small simulation study I will develop a lineup protocol for visual inference to investigate there is a statistically significant connection between calorie and sodium content in fast food items across various restaurants. In order to do this I have found a TidyTuesday dataset that includes nutritional information sourced from fastfoodnutrition.org. In order to test this possible relation I will use plots to determine if there is a connection that is more extreme than what would be expected under a null hypothesis of no correlation between calorie content and sodium content. If the representative plot is recognizable amongst many null plots, then the relationship is not due to pure chance and we have visual evidence to prove this. I chose to explore this relationship due to the importance of health and understanding what you are eating. Calories and sodium are two of the most prominent factors when it comes to eating healthier, so I wanted to find out if they also correlated with one another.\n\ncalories_sodium &lt;- fastfood %&gt;%\n  filter(!is.na(calories), !is.na(sodium)) %&gt;% \n  select(item, restaurant, calories, sodium) # filtering to get only the food item, calories, and sodium that are not NA.\n\nnull &lt;- function(data) { \n  data %&gt;%\n    mutate(sodium = sample(sodium)) # permutes sodium values to create a 'null' dataset\n}\n\nnull_data &lt;- map(1:19, ~null(calories_sodium) %&gt;%\n                   mutate(plot_id = as.character(.x))) # generate 19 null datasets\n\ntrue_data &lt;- calories_sodium %&gt;% \n  mutate(plot_id = \"20\") # set the true data to plot 20\n\ncombine_data &lt;- bind_rows(null_data) %&gt;%\n  bind_rows(true_data) %&gt;% # combines the null data with the true data\n  mutate(plot_id = fct_shuffle(factor(plot_id)))  # shuffles plots based on plot id\n\nggplot(combine_data, aes(x = calories, y = sodium)) + # plot calories and sodium\n  geom_point() + # plot points\n  geom_smooth() + # plot line\n  facet_wrap(~plot_id) + # creates 20 plots from the null and true data\n  labs( # create labels for the graphs\n    title = \"Calories vs. Sodium in Fast Food Items\",\n    x = \"Calories\",\n    y = \"Sodium\"\n  )\n\n\n\n\n\n\n\n\nThe plots above represent 19 simulated versions of the fast food data, with one plot showing the real data and relationship between calories and sodium as observed from the TidyTuesday dataset. The others randomly shuffled the sodium values in order to create randomization and remove association between calories and sodium. When reviewing all the plots, plot 20 stands out with a strong positive linear relationship. Plot 20 also corresponds to the real data, providing evidence that there is a true connection in the relationship between calories and sodium. The other simulated plots contain variously scattered data points, ultimately resulting in pretty flat lines with no true relationship or pattern observed. Thus, we have evidence a true statistical relationship between higher calories and more sodium content in fast food items."
  },
  {
    "objectID": "project3.html#end-description",
    "href": "project3.html#end-description",
    "title": "Fast Food",
    "section": "End Description",
    "text": "End Description\nIn this lineup protocol for visual inference simulation, I cleaned the fast food dataset from TidyTuesday in order to observe a potential relationship between calories and sodium. I created a function to create simulated/null datasets, which I then put side by side with a graph of the real data to see if the real data stood out amongst the others. From this, we were able to easily identify the plot of real data as discussed above, providing evidence that there is a strong correlation between higher calories and higher sodium content in fast food items. There is a clear relationship between food items with a high calorie and high sodium content. While these fast food places do likely have some healthy options, they are lower in calorie and sodium content. A high calorie/high sodium food item is often see as more unhealthy. Based on our findings we see a connection between the two, likely because each are signs of food being unhealthy. We see statistical evidence of a correlation between the two and that food items having both high calories and high sodium was not a result of chance."
  },
  {
    "objectID": "project3.html#references",
    "href": "project3.html#references",
    "title": "Fast Food",
    "section": "References",
    "text": "References\n“Fast Food Nutrition.” Fast Food Nutrition, https://fastfoodnutrition.org/. Accessed 7 May 2025.\nHughes, Ellis. “Fast Food Entree Data.” Github, 2018, https://github.com/rfordatascience/tidytuesday/tree/main/data/2018/2018-09-04."
  }
]